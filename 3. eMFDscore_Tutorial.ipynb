{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eMFDscore Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Media Neuroscience Lab  \n",
    "October 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a tutorial on how to use eMFDScore for extracing various moral information metrics from texutal input.  \n",
    "Specifically, this tutorial guides the reader how to effectively use the eMFDScore tool either on the command line (for MACOS and Linux) and in Python (for Windows, MACOS, and Linux).  \n",
    "In addition, this tutorial also demonstrates which scoring options are appropriate for particular tasks.  \n",
    "For more detailed background information on the eMFD, please consult the respective [publication](https://link.springer.com/article/10.3758/s13428-020-01433-0).\n",
    "\n",
    "Finally, when using eMFDscore, please consider \"starring\" the Github repository and citing the follwing article: \n",
    "\n",
    "Hopp, F. R., Fisher, J. T., Cornell, D., Huskey, R., & Weber, R. (2020). The extended Moral Foundations Dictionary (eMFD):  \n",
    "Development and applications of a crowd-sourced approach to extracting moral intuitions from text.   \n",
    "_Behavior Research Methods_, https://doi.org/10.3758/s13428-020-01433-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interactively run this tutorial, you should clone the eMFDscore github repository and follow the install instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set-up Your Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eMFDscore requires a Python installation (v3.7+). If your machine does not have Python installed,  \n",
    "we recommend installing Python by downloading and installing either Anaconda or Miniconda for your OS.\n",
    "\n",
    "For best practises, we recommend installing eMFDscore into a virtual conda environment.  \n",
    "Hence, you should first create a virtual environment by executing the following command in your terminal:\n",
    "\n",
    "`$ conda create -n emfd python=3.7` \n",
    "\n",
    "Once Anaconda/Miniconda is installed activate the env via:\n",
    "\n",
    "`$ source activate emfd`\n",
    "\n",
    "Next, you must install spaCy, which is the main natural language processing backend that eMFDscore is built on:\n",
    "\n",
    "`$ conda install -c conda-forge spacy`  \n",
    "`$ python -m spacy download en_core_web_sm`\n",
    "\n",
    "Finally, you can install eMFDscore by copying, pasting, and executing the following command:\n",
    "\n",
    "`pip install https://github.com/medianeuroscience/emfdscore/archive/master.zip`\n",
    "\n",
    "In addition, if you plan to run eMFDscore in an interactive python environment (IPython) or using jupyter notebooks, we encourage you to install jupyter-lab into the eMFD environment:  \n",
    "`conda install -c conda-forge jupyterlab`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using eMFDScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eMFDScore is a versatile tool that can either be run using the command line or directly from Python.  \n",
    "Note that if you are on a **Windows** machine, you must run eMFDscore from a Python environment. \n",
    "\n",
    "In this tutorial, we will load a few packages to inspect the output of eMFDScore's computed metrics.  \n",
    "These packages must be installed/available in your conda environment, but are not necessary for  \n",
    "eMFDscore to run properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for Document Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With eMFDScore, you have several options to extract moral information metrics from texutal corpora.   \n",
    "Below, we go over these options one by one.  \n",
    "\n",
    "When scoring documents with the extended Moral Foundations Dicitonary (eMFD; default in eMFDScore),  \n",
    "you must decide how you would like to use the eMFD for scoring textual documents.  \n",
    "\n",
    "As a reminder, in the eMFD, every of the 3020 words is assigned the following scores: \n",
    "- `Foundation Probabilities`: Each word is assigned 5 probabalities that denote the likelihood  \n",
    "that this word is associated with each one of the five moral foundations as identified by Moral  \n",
    "Foundations  Theory. For example, the word \"kill\" has a care probability of 0.4 and  \n",
    "a loyalty probability of 0.24, meaning that there is a 40% chance that a coder highlighted a context in which the word \"kill\" appeared  \n",
    "with the care-harm foundation and a 24% chance that this context was highlighted with the loyalty-betrayal foundation.\n",
    "\n",
    "- `Sentiment Scores`: Each word is assigned 5 sentiment scores that denote the average sentiment  \n",
    "of the foundation context in which this word appeared. For example, the word \"kill\" has an average  \n",
    "\"care_sent\" of -0.69, meaning that all \"care-harm\" highlights in which \"kill\" appeared had an average,  \n",
    "negative sentiment of -0.69.\n",
    "\n",
    "***\n",
    "\n",
    "Based on these scores, there are two options how these scores can be \"mapped\" when scoring a  \n",
    "document (flag `prob_map` below):\n",
    "\n",
    "1. Use `all` probabilities per word in the eMFD (option `all`):  \n",
    "=> Using all five foundation probabilities assumes that each word is used as an indicator for multiple foundations with the probabilities as weights. \n",
    "2. Assign a `single`  probability to each word in the eMFD according to the foundation with the highest  probability (option `single`):  \n",
    "=> Each word only indicates **one** foundation (the one with the highest foundation probability) and each time this word is found  \n",
    "the respective foundation is increased by that word's foundation probability.\n",
    "\n",
    "***\n",
    "\n",
    "In addition, you can decide whether you want eMFDScore to return the average sentiment for each  \n",
    "foundation, or whether you would like eMFDScore to split each foundation  \n",
    "into a `vice` and `virtue`  category (flag `output_metrics` below):\n",
    "\n",
    "1. Return the average `sentiment ` for each foundation (option `sentiment`) \n",
    "2. Split foundations into a `vice-virtue` category (option `vice-virtue`). \n",
    "\n",
    "The vice-virtue split is accomplished by considering the average sentiment of each foundation of each  \n",
    "word, and then assigning this word to \"virtue\" if the foundation sentiment is positive,  \n",
    "or to \"vice\" if the sentiment is negative.  \n",
    "For instance, if using the `all` option for the `prob_map` option above, a word's foundation probabilities  \n",
    "will be translated into five `virtue` scores (e.g., care, fairness,  loyalty, authority, and sanctity)   \n",
    "if the word's sentiment for these foundations is positive, whereas a word  whose sentiments for each  \n",
    "foundation is negative will be assigned five `vice` scores (e.g., harm, cheating,  betrayal, subversion, and degradation). \n",
    "\n",
    "***\n",
    "\n",
    "Based on the above, there is a total of 4 different options how the eMFD can be used.  \n",
    "The specific usage of each and use case is explicated below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eMFDScore Command-Line Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical command for eMFDScore specifies the following:\n",
    "\n",
    "`$ emfdscore [INPUT_FILE][OUTPUT_FILE][SCORING_METHOD][DICT_TYPE[prob-map][output_metrics]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using eMFDscore, several inputs need to be defined in a specific order: \n",
    "\n",
    "- [INPUT_FILE]: = The path to a CSV file in which the first column contains the document texts to be scored.  \n",
    "  Each row should reflect its own document. See the template_input.csv for an example file format.\n",
    "  \n",
    "  \n",
    "- [OUTPUT_FILE] = Specifies the file name of the generated output csv.\n",
    "\n",
    "\n",
    "- [SCORING_METHOD] = Currently, eMFDscore employs three different scoring algorithms:\n",
    "    - `bow` is a classical Bag-of-Words approach in which the algorithm simply searches for word matches between document texts and the specified dictionary.\n",
    "    - `pat` (in development) relies on named entity recognition and syntactic dependency parsing. For each document, the algorithm first extracts all mentioned entities.  \n",
    "    Next, for each entitiy, eMFDscore extracts words that pertain to 1) moral verbs for which the entity is an agent argument (Agent verbs), 2) moral verbs for  \n",
    "    which the entity is the patient, theme, or other argument (Patient verbs), and other moral attributes (i.e., adjectival modifiers, appositives, etc.).\n",
    "    - `wordlist` is a simple scoring algorithm that lets users examine the moral content of individual words. This scoring method expects a CSV where each row corresponds  \n",
    "    to a unique word. Note: The wordlist scoring algorithm does not perform any tokenization or preprocessing on the wordlists.   \n",
    "    For a more fine-grained moral content extraction, users are encouraged to use either the bow or path methodology. Furthermore, only the emfd is currenlty supported for PAT extraction.   \n",
    "    Additionally, this method is more computationally expensive and thus has a longer execution time.\n",
    "    - `gdelt.ngrams` is designed for the Global Database of Events, Language, and Tone Television Ngram dataset.   \n",
    "    This scoring method expects a unigram (1gram) input text file from GDELT and will score each unprocessed (untokenized) unigram with the eMFD.\n",
    "    \n",
    "    \n",
    "- [DICTIONARY_TYPE] = Declares which dictionary is applied to score documents. In its current version, eMFDscore lets users choose between three dictionaries:\n",
    "    - `emfd` = extended Moral Foundations Dictionary (eMFD)\n",
    "    - `mfd2` = Moral Foundations Dicitonary 2.0 (Frimer et al., 2017; https://osf.io/xakyw/ )\n",
    "    - `mfd` = original Moral Foundations Dictionary (https://moralfoundations.org/othermaterials)\n",
    "\n",
    "\n",
    "- When choosing the eMFD; the following two additional flags need to be defined:\n",
    "    - [PROB_MAP]: How are the foundation probabilities mapped when scoring a document? \n",
    "        - `all` : use all probabilities per word in the eMFD\n",
    "        - `single`: Assign a single probability to each word in the eMFD according to the foundation with the highest probability\n",
    "           \n",
    "    - [OUTPUT_METRICS]: Which metrics are returned? \n",
    "        - `sentiment`: Return the average sentiment for each foundation\n",
    "        - `vice-virtue`: Split foundations into a vice-virtue category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Documents with the eMFD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we illustrate the various text scoring options in eMFDscore.  \n",
    "For this purpose, we will be using a CSV file in which each row corresponds to  \n",
    "a news article text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A pair of US senators are asking the Biden adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's little evidence the Delta variant can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The stark disparity between low and high vacci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Surgeon General Dr. Vivek Murthy says he is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong Un fired several senior officials who...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  A pair of US senators are asking the Biden adm...\n",
       "1  There's little evidence the Delta variant can ...\n",
       "2  The stark disparity between low and high vacci...\n",
       "3  US Surgeon General Dr. Vivek Murthy says he is...\n",
       "4  Kim Jong Un fired several senior officials who..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_input = pd.read_csv('test.csv', header=None)\n",
    "template_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(template_input.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82389 entries, 0 to 82388\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       82389 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 643.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#template_input = template_input.rename(columns={\"Message\": \"0\"})\n",
    "template_input.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A pair of US senators are asking the Biden adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's little evidence the Delta variant can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The stark disparity between low and high vacci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Surgeon General Dr. Vivek Murthy says he is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kim Jong Un fired several senior officials who...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  A pair of US senators are asking the Biden adm...\n",
       "1  There's little evidence the Delta variant can ...\n",
       "2  The stark disparity between low and high vacci...\n",
       "3  US Surgeon General Dr. Vivek Murthy says he is...\n",
       "4  Kim Jong Un fired several senior officials who..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_input = pd.read_csv('covid_data.csv', usecols=[\"Message\"])\n",
    "#template_input = template_input.rename(columns={\"Message\": \"0\"})\n",
    "template_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_input.to_csv('new_covid_df.csv', header=None, index=False)\n",
    "template_input = pd.read_csv('new_covid_df.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use All Probabilities per Word and Return Sentiment Scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option should be used when one wants to extract the overall, holistic moral signal from a document.  \n",
    "Note that because each word is assigned five foundation probabilities, there exist higher correlations  \n",
    "across these foundations, making this method less suitable when one wants to\n",
    "- use the foundation probabilities as predictor variables in statistical models\n",
    "- discriminate which foundations are more or less represented in a text.  \n",
    "\n",
    "For these cases, options (2) and (4) below  should be preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 11:50:14.869489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Processed: 82389 100% |❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤| Elapsed Time: 0:04:20 Time:  0:04:20\n"
     ]
    }
   ],
   "source": [
    "from emfdscore.scoring import score_docs \n",
    "\n",
    "num_docs = len(template_input)\n",
    "\n",
    "DICT_TYPE = 'emfd'\n",
    "PROB_MAP = 'all'\n",
    "SCORE_METHOD = 'bow'\n",
    "OUT_METRICS = 'sentiment'\n",
    "OUT_CSV_PATH = 'all-sent.csv'\n",
    "\n",
    "df = score_docs(template_input,DICT_TYPE,PROB_MAP,SCORE_METHOD,OUT_METRICS,num_docs)\n",
    "df.to_csv(OUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (3.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.10.0)\n",
      "Requirement already satisfied: pathy in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: jinja2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (65.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from pathy->spacy) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 11:57:16.921398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.10)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.17)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.21.5)\n",
      "Requirement already satisfied: setuptools in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (65.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.27.1)\n",
      "Requirement already satisfied: pathy in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: jinja2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/brinxu/opt/anaconda3/lib/python3.9/site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key does not exist\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "print(dictionary.get(0, \"Key does not exist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data combinnation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care_p</th>\n",
       "      <th>fairness_p</th>\n",
       "      <th>loyalty_p</th>\n",
       "      <th>authority_p</th>\n",
       "      <th>sanctity_p</th>\n",
       "      <th>care_sent</th>\n",
       "      <th>fairness_sent</th>\n",
       "      <th>loyalty_sent</th>\n",
       "      <th>authority_sent</th>\n",
       "      <th>sanctity_sent</th>\n",
       "      <th>moral_nonmoral_ratio</th>\n",
       "      <th>f_var</th>\n",
       "      <th>sent_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090455</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.130082</td>\n",
       "      <td>0.139355</td>\n",
       "      <td>0.085406</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>-0.095777</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>-0.070749</td>\n",
       "      <td>-0.175241</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.004499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134069</td>\n",
       "      <td>0.113038</td>\n",
       "      <td>0.085576</td>\n",
       "      <td>0.090797</td>\n",
       "      <td>0.088874</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.090464</td>\n",
       "      <td>0.142080</td>\n",
       "      <td>0.086809</td>\n",
       "      <td>0.046238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128494</td>\n",
       "      <td>0.126324</td>\n",
       "      <td>0.108211</td>\n",
       "      <td>0.083956</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>-0.120624</td>\n",
       "      <td>-0.086392</td>\n",
       "      <td>-0.081137</td>\n",
       "      <td>-0.065666</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     care_p  fairness_p  loyalty_p  authority_p  sanctity_p  care_sent  \\\n",
       "0  0.090455    0.119205   0.130082     0.139355    0.085406  -0.121268   \n",
       "1  0.134069    0.113038   0.085576     0.090797    0.088874   0.042614   \n",
       "2  0.128494    0.126324   0.108211     0.083956    0.093256  -0.120624   \n",
       "\n",
       "   fairness_sent  loyalty_sent  authority_sent  sanctity_sent  \\\n",
       "0      -0.095777      0.006735       -0.070749      -0.175241   \n",
       "1       0.090464      0.142080        0.086809       0.046238   \n",
       "2      -0.086392     -0.081137       -0.065666      -0.057119   \n",
       "\n",
       "   moral_nonmoral_ratio     f_var  sent_var  \n",
       "0              0.777778  0.000574  0.004499  \n",
       "1              1.000000  0.000429  0.001634  \n",
       "2              0.777778  0.000388  0.000599  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all-sent.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/13/92pq4q957ljckd_vxp8nd8m80000gn/T/ipykernel_4366/2221778967.py:1: DtypeWarning: Columns (32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv('covid_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Name</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Facebook Id</th>\n",
       "      <th>Page Category</th>\n",
       "      <th>Page Admin Top Country</th>\n",
       "      <th>Page Description</th>\n",
       "      <th>Page Created</th>\n",
       "      <th>Likes at Posting</th>\n",
       "      <th>Followers at Posting</th>\n",
       "      <th>Post Created</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Views</th>\n",
       "      <th>Total Views For All Crossposts</th>\n",
       "      <th>URL</th>\n",
       "      <th>Message</th>\n",
       "      <th>Link</th>\n",
       "      <th>Link Text</th>\n",
       "      <th>Description</th>\n",
       "      <th>Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )</th>\n",
       "      <th>LNC_category</th>\n",
       "      <th>covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>cnn</td>\n",
       "      <td>5550296508</td>\n",
       "      <td>MEDIA_NEWS_COMPANY</td>\n",
       "      <td>US</td>\n",
       "      <td>Instant breaking news alerts and the most talk...</td>\n",
       "      <td>2007-11-07 22:14:27</td>\n",
       "      <td>34563652</td>\n",
       "      <td>38358192.0</td>\n",
       "      <td>2021-06-30 13:00:28 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/5550296508/posts/1016...</td>\n",
       "      <td>A pair of US senators are asking the Biden adm...</td>\n",
       "      <td>https://cnn.it/3dpOHxJ</td>\n",
       "      <td>Senators ask DOT to remove expiration date for...</td>\n",
       "      <td></td>\n",
       "      <td>-3.81</td>\n",
       "      <td>liberal</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>cnn</td>\n",
       "      <td>5550296508</td>\n",
       "      <td>MEDIA_NEWS_COMPANY</td>\n",
       "      <td>US</td>\n",
       "      <td>Instant breaking news alerts and the most talk...</td>\n",
       "      <td>2007-11-07 22:14:27</td>\n",
       "      <td>34563652</td>\n",
       "      <td>38358192.0</td>\n",
       "      <td>2021-06-30 12:00:50 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/5550296508/posts/1016...</td>\n",
       "      <td>There's little evidence the Delta variant can ...</td>\n",
       "      <td>https://cnn.it/3heEWmU</td>\n",
       "      <td>Rise of Delta variant brings mask question bac...</td>\n",
       "      <td></td>\n",
       "      <td>1.72</td>\n",
       "      <td>liberal</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>cnn</td>\n",
       "      <td>5550296508</td>\n",
       "      <td>MEDIA_NEWS_COMPANY</td>\n",
       "      <td>US</td>\n",
       "      <td>Instant breaking news alerts and the most talk...</td>\n",
       "      <td>2007-11-07 22:14:27</td>\n",
       "      <td>34563652</td>\n",
       "      <td>38358192.0</td>\n",
       "      <td>2021-06-30 09:27:09 EDT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/5550296508/posts/1016...</td>\n",
       "      <td>The stark disparity between low and high vacci...</td>\n",
       "      <td>https://cnn.it/2UbdFdl</td>\n",
       "      <td>Fauci warns there may soon be 'two Americas' a...</td>\n",
       "      <td></td>\n",
       "      <td>2.63</td>\n",
       "      <td>liberal</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Page Name User Name  Facebook Id       Page Category Page Admin Top Country  \\\n",
       "0       CNN       cnn   5550296508  MEDIA_NEWS_COMPANY                     US   \n",
       "1       CNN       cnn   5550296508  MEDIA_NEWS_COMPANY                     US   \n",
       "2       CNN       cnn   5550296508  MEDIA_NEWS_COMPANY                     US   \n",
       "\n",
       "                                    Page Description         Page Created  \\\n",
       "0  Instant breaking news alerts and the most talk...  2007-11-07 22:14:27   \n",
       "1  Instant breaking news alerts and the most talk...  2007-11-07 22:14:27   \n",
       "2  Instant breaking news alerts and the most talk...  2007-11-07 22:14:27   \n",
       "\n",
       "   Likes at Posting  Followers at Posting             Post Created  ...  \\\n",
       "0          34563652            38358192.0  2021-06-30 13:00:28 EDT  ...   \n",
       "1          34563652            38358192.0  2021-06-30 12:00:50 EDT  ...   \n",
       "2          34563652            38358192.0  2021-06-30 09:27:09 EDT  ...   \n",
       "\n",
       "  Total Views Total Views For All Crossposts  \\\n",
       "0           0                              0   \n",
       "1           0                              0   \n",
       "2           0                              0   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.facebook.com/5550296508/posts/1016...   \n",
       "1  https://www.facebook.com/5550296508/posts/1016...   \n",
       "2  https://www.facebook.com/5550296508/posts/1016...   \n",
       "\n",
       "                                             Message                    Link  \\\n",
       "0  A pair of US senators are asking the Biden adm...  https://cnn.it/3dpOHxJ   \n",
       "1  There's little evidence the Delta variant can ...  https://cnn.it/3heEWmU   \n",
       "2  The stark disparity between low and high vacci...  https://cnn.it/2UbdFdl   \n",
       "\n",
       "                                           Link Text  Description  \\\n",
       "0  Senators ask DOT to remove expiration date for...                \n",
       "1  Rise of Delta variant brings mask question bac...                \n",
       "2  Fauci warns there may soon be 'two Americas' a...                \n",
       "\n",
       "   Overperforming Score (weighted  —  Likes 1x Shares 1x Comments 1x Love 1x Wow 1x Haha 1x Sad 1x Angry 1x Care 1x )  \\\n",
       "0                                              -3.81                                                                    \n",
       "1                                               1.72                                                                    \n",
       "2                                               2.63                                                                    \n",
       "\n",
       "   LNC_category  covid  \n",
       "0       liberal  covid  \n",
       "1       liberal  covid  \n",
       "2       liberal  covid  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv('covid_data.csv')\n",
    "original_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat([original_df, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.to_csv(\"covid_data_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions or Concerns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any questions or concerns, please open an [issue](https://github.com/medianeuroscience/emfdscore/issues) on the Github repository.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
